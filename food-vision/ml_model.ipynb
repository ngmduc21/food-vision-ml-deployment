{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Khai báo các thư hiện cần thiết"
      ],
      "outputs": [],
      "metadata": {
        "id": "ihw2vm6mvejh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "import zipfile\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.layers.experimental import preprocessing\r\n",
        "\r\n",
        "# Giải nén file tải xuống\r\n",
        "def unzip_data(filename):\r\n",
        "  \"\"\"\r\n",
        "  Function giải nén file.\r\n",
        "  \"\"\"\r\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\r\n",
        "  zip_ref.extractall()\r\n",
        "  zip_ref.close()"
      ],
      "outputs": [],
      "metadata": {
        "id": "B9mWNZS9vnPc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "# Khai báo kiểu tập dữ liệu train và test\r\n",
        "IMG_SIZE = (224, 224)\r\n",
        "\r\n",
        "def create_data_loaders(train_dir, test_dir, image_size=IMG_SIZE):\r\n",
        "  \"\"\"\r\n",
        " Tạo tập data train và data test BatchDataset từ train_dir và test_dir.\r\n",
        "  \"\"\"\r\n",
        "  train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\r\n",
        "                                                                  label_mode=\"categorical\",\r\n",
        "                                                                  image_size=image_size)\r\n",
        "  \r\n",
        "  test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\r\n",
        "                                                                  label_mode=\"categorical\",\r\n",
        "                                                                  image_size=image_size)\r\n",
        "  \r\n",
        "  return train_data, test_data"
      ],
      "outputs": [],
      "metadata": {
        "id": "TavN1v7uvo2U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "# Tăng cường data với các trường hợp xoay, lật ngang, thu phóng...\r\n",
        "data_augmentation = keras.Sequential([\r\n",
        "  preprocessing.RandomFlip(\"horizontal\"),\r\n",
        "  preprocessing.RandomRotation(0.2),\r\n",
        "  preprocessing.RandomZoom(0.2),\r\n",
        "  preprocessing.RandomHeight(0.2),\r\n",
        "  preprocessing.RandomWidth(0.2),\r\n",
        "  # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\r\n",
        "], name =\"data_augmentation\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "bfQCbNqmvwmI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "# Thiết lập input shape và khởi tạo model với các layer cần thiết\r\n",
        "INPUT_SHAPE = (224, 224, 3)\r\n",
        "BASE_MODEL = tf.keras.applications.EfficientNetB0(include_top=False)\r\n",
        "\r\n",
        "def create_model(input_shape=INPUT_SHAPE, base_model=BASE_MODEL, num_classes=10):\r\n",
        "  \r\n",
        "  base_model.trainable = False\r\n",
        "\r\n",
        "  # Khởi tạo input layer\r\n",
        "  inputs = layers.Input(shape=input_shape, name=\"input_layer\")\r\n",
        "\r\n",
        "  # Thêm giai đoạn tăng cường data thành 1 layer\r\n",
        "  x = data_augmentation(inputs)\r\n",
        "\r\n",
        "  # cho model cơ sở 1 đầu vào nhưng không train\r\n",
        "  x = base_model(x, training=False)\r\n",
        "\r\n",
        "  # Tạo layer Pooling2D\r\n",
        "  x = layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\r\n",
        "\r\n",
        "  # Đặt layer dense ở output\r\n",
        "  outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\r\n",
        "\r\n",
        "  # khai báo model với 2 đầu input và output\r\n",
        "  model = keras.Model(inputs, outputs)\r\n",
        "\r\n",
        "  # Compile the model\r\n",
        "  model.compile(loss=\"categorical_crossentropy\",\r\n",
        "                optimizer=tf.keras.optimizers.Adam(),\r\n",
        "                metrics=[\"accuracy\"])\r\n",
        "  \r\n",
        "  return model"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n",
            "16711680/16705208 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fNLDKMjv2ML",
        "outputId": "8cc1ba48-b630-45c5-af46-d3d5a9573689"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "source": [
        "# Function để import ảnh và resize lại để nhập vào model\r\n",
        "def load_and_prep_image(filename, img_shape=224, scale=False):\r\n",
        "  \"\"\"\r\n",
        "  Đọc dữ liệu ảnh từ filename, decode lại và chuyển thành kích thước\r\n",
        "  (224, 224, 3).\r\n",
        "  \"\"\"\r\n",
        "  # Đọc ảnh vào\r\n",
        "  img = tf.io.read_file(filename)\r\n",
        "  # Decode lại\r\n",
        "  img = tf.image.decode_jpeg(img)\r\n",
        "  # Resize ảnh\r\n",
        "  img = tf.image.resize(img, [img_shape, img_shape])\r\n",
        "  # Rescale ảnh (get all values between 0 and 1)\r\n",
        "  if scale:\r\n",
        "    return img/255.\r\n",
        "  else:\r\n",
        "    return img"
      ],
      "outputs": [],
      "metadata": {
        "id": "5YvUnQahv2NO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "# Tải xuống tập data để train\r\n",
        "import zipfile\r\n",
        "\r\n",
        "# Tải data (10 class subset of Food101 - https://www.kaggle.com/dansbecker/food-101)\r\n",
        "\r\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\r\n",
        "\r\n",
        "unzip_data(\"10_food_classes_all_data.zip\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "'wget' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkAhTkmfwM6G",
        "outputId": "e5975cc9-94dd-4ddc-9d02-3de21616b178"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "# Tạo tensorboard callback\r\n",
        "import datetime\r\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\r\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\r\n",
        "      log_dir=log_dir\r\n",
        "  )\r\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\r\n",
        "  return tensorboard_callback"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q1fKXpsywQPo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "# Tạo BatchDataset\r\n",
        "train_data, test_data = create_data_loaders(train_dir=\"10_food_classes_all_data/train/\",\r\n",
        "                                            test_dir=\"10_food_classes_all_data/test/\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7500 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6czxvWXpwS4-",
        "outputId": "77ed6753-d183-4579-8c4f-8a3b15fbb8f8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "# Kiểm tra data train\r\n",
        "train_data"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((None, 224, 224, 3), (None, 10)), types: (tf.float32, tf.float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf5Vt4jPwU_U",
        "outputId": "d437889f-f388-4f86-b36e-bd83cd19b681"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "# Tạo model\r\n",
        "model_1 = create_model(num_classes=len(train_data.class_names))\r\n",
        "\r\n",
        "# Train model\r\n",
        "history_1_percent = model_1.fit(train_data,\r\n",
        "                    epochs=5,\r\n",
        "                    steps_per_epoch=len(train_data),\r\n",
        "                    validation_data=test_data,\r\n",
        "                    validation_steps=int(0.25 * len(test_data)), # validate for less steps\r\n",
        "                    # Track model training logs\r\n",
        "                    callbacks=[create_tensorboard_callback(\"transfer_learning\", \"all_data_aug\")])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: transfer_learning/all_data_aug/20211113-181703\n",
            "Epoch 1/5\n",
            "235/235 [==============================] - 476s 2s/step - loss: 1.4580 - accuracy: 0.5497 - val_loss: 0.4722 - val_accuracy: 0.8701\n",
            "Epoch 2/5\n",
            "235/235 [==============================] - 380s 2s/step - loss: 0.7374 - accuracy: 0.7699 - val_loss: 0.4243 - val_accuracy: 0.8750\n",
            "Epoch 3/5\n",
            "235/235 [==============================] - 361s 2s/step - loss: 0.6411 - accuracy: 0.7985 - val_loss: 0.3574 - val_accuracy: 0.8980\n",
            "Epoch 4/5\n",
            "235/235 [==============================] - 374s 2s/step - loss: 0.5888 - accuracy: 0.8150 - val_loss: 0.3459 - val_accuracy: 0.9030\n",
            "Epoch 5/5\n",
            "235/235 [==============================] - 365s 2s/step - loss: 0.5609 - accuracy: 0.8285 - val_loss: 0.3403 - val_accuracy: 0.9013\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoTediMuwbBZ",
        "outputId": "bf48d62e-0805-4b72-d0a1-5ce256dcf4cc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "source": [
        "# Save model_1\r\n",
        "model_1.save(\"efficientnet_model_1_10_classes\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: efficientnet_model_1_10_classes\\assets\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "uIU9Q_16wgR8",
        "outputId": "cc93495e-8a09-43bd-bbb7-2b6b388f2f42"
      }
    }
  ],
  "metadata": {
    "colab": {
      "name": "ml_model.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "ebd3d42607388af7a3d5aa59e4eed1638b2a6a14bf60c8278b9a552dd0a5bc13"
    },
    "kernelspec": {
      "display_name": "Python 3.8.9 64-bit",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}